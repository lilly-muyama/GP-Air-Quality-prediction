{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84566dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "from math import sqrt\n",
    "sys.path.append('../..')\n",
    "from modules import utils\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import tensorflow_probability as tfp\n",
    "tfk = tf.keras\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "tfd = tfp.distributions\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b993d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0eb130",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_log_likelihood = lambda x, rv_x: -rv_x.log_prob(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfe193b",
   "metadata": {},
   "source": [
    "#### The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d389bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "jinja_df = pd.read_csv('../data/jinja_data.csv', parse_dates=['timestamp'])\n",
    "jinja_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55477ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "latitudes = jinja_df['latitude'].unique()\n",
    "longitudes = jinja_df['longitude'].unique()\n",
    "device_ids = jinja_df['device_number'].unique()\n",
    "len(latitudes), len(longitudes), len(device_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da366ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame()\n",
    "cols = ['timestamp', 'latitude', 'longitude', 'pm2_5_calibrated_value']\n",
    "for i, device_id in enumerate(device_ids):\n",
    "    device_df = utils.get_device_data(jinja_df, device_id, cols)\n",
    "    processed_df = utils.preprocessing(device_df)\n",
    "    final_df = pd.concat([final_df, processed_df])\n",
    "final_df.reset_index(drop=True, inplace=True)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3f3876",
   "metadata": {},
   "source": [
    "#### Model training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13985766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bnn(X_train, y_train, epochs=1000, optimizer='RMSProp', dropout=0.2):\n",
    "\n",
    "    prior = tfd.Independent(tfd.Normal(loc=tf.zeros(1, dtype=tf.float64), scale=1.0), \n",
    "                            reinterpreted_batch_ndims=1)\n",
    "    model = tfk.Sequential([\n",
    "        tfk.layers.InputLayer(input_shape=(3,), name='input'),\n",
    "        tfk.layers.Dropout(dropout, name='dropout1'),\n",
    "        tfk.layers.Dense(10, activation='relu', name='dense_1'),\n",
    "        tfk.layers.Dropout(dropout, name='dropout2'),\n",
    "        tfk.layers.Dense(tfp.layers.MultivariateNormalTriL.params_size(1), activation=None, name='distribution_weights'),\n",
    "        tfk.layers.Dropout(dropout, name='dropout3'),\n",
    "        tfp.layers.MultivariateNormalTriL(1, activity_regularizer=tfp.layers.KLDivergenceRegularizer(prior, weight=1/32), \n",
    "                                          name='output')], name='model')\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss=tf.keras.losses.MeanSquaredError())\n",
    "    checkpoint = ModelCheckpoint('../models/bnn_checkpoint.h5', monitor='val_loss', save_best_only=True,\n",
    "                                save_weights_only=False)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=300)\n",
    "    model.fit(X_train, y_train, batch_size=32, epochs=epochs, callbacks=[checkpoint, early_stopping], \n",
    "              validation_split=0.2)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b17ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(final_df, idx):\n",
    "    device_indices = final_df[final_df.latitude==latitudes[idx]].index\n",
    "    device_df = jinja_df[jinja_df.device_number == device_ids[idx]]\n",
    "    assert(len(device_indices) == len(device_df)-device_df.pm2_5_calibrated_value.isna().sum())\n",
    "    \n",
    "    test_df = final_df.loc[device_indices]\n",
    "    assert(len(test_df.longitude.unique()) == 1)\n",
    "    \n",
    "    train_df = pd.concat([final_df, test_df]).drop_duplicates(keep=False)\n",
    "    assert(len(train_df.longitude.unique()) == len(longitudes)-1)\n",
    "    assert len(final_df) == len(test_df) + len(train_df)\n",
    "    \n",
    "    \n",
    "    X_train = train_df.iloc[:, 0:-1]\n",
    "    y_train = train_df.iloc[:, -1]\n",
    "#     data_train =tf.data.Dataset.from_tensor_slices((X_train.values, y_train.values))\n",
    "#     data_train = data_train.batch(32).repeat(n_epochs)\n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)#.reshape(-1, 1)\n",
    "    \n",
    "    X_test = test_df.iloc[:, 0:-1]\n",
    "    y_test = test_df.iloc[:, -1]\n",
    "#     data_test =tf.data.Dataset.from_tensor_slices((X_test.values, y_test.values))\n",
    "#     data_test = data_test.batch(1)\n",
    "    X_test, y_test = np.array(X_test), np.array(y_test)#.reshape(-1, 1)\n",
    "    \n",
    "    model = bnn(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2b3fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_list = []\n",
    "for i in range(len(latitudes)):\n",
    "    rmse = cross_validation(final_df, i)\n",
    "    rmse_list.append(rmse)\n",
    "    print(f'{device_ids[i]} successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f1a83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rmse = np.mean(rmse_list)          \n",
    "mean_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd724ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be791035",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
