{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6746f8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import random\n",
    "import os\n",
    "from math import sqrt\n",
    "sys.path.append('../..')\n",
    "from modules import utils\n",
    "import gpytorch\n",
    "import math\n",
    "import torch\n",
    "import tqdm\n",
    "import gpytorch\n",
    "from gpytorch.means import ConstantMean, LinearMean\n",
    "from gpytorch.kernels import RBFKernel, ScaleKernel\n",
    "from gpytorch.variational import VariationalStrategy, CholeskyVariationalDistribution\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "from gpytorch.models import ApproximateGP, GP\n",
    "from gpytorch.mlls import VariationalELBO, AddedLossTerm\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.models.deep_gps import DeepGPLayer, DeepGP\n",
    "from gpytorch.mlls import DeepApproximateMLL\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c36b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84200c3a",
   "metadata": {},
   "source": [
    "#### The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90147e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "jinja_df = pd.read_csv('../data/jinja_data.csv', parse_dates=['timestamp'])\n",
    "jinja_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2fbbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "latitudes = jinja_df['latitude'].unique()\n",
    "longitudes = jinja_df['longitude'].unique()\n",
    "device_ids = jinja_df['device_number'].unique()\n",
    "len(latitudes), len(longitudes), len(device_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a663800",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame()\n",
    "cols = ['timestamp', 'latitude', 'longitude', 'pm2_5_calibrated_value']\n",
    "for i, device_id in enumerate(device_ids):\n",
    "    device_df = utils.get_device_data(jinja_df, device_id, cols)\n",
    "    processed_df = utils.preprocessing(device_df)\n",
    "    final_df = pd.concat([final_df, processed_df])\n",
    "final_df.reset_index(drop=True, inplace=True)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2577248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden_dims = 1\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17828c7d",
   "metadata": {},
   "source": [
    "#### Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc72ecbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepGPHiddenLayer(DeepGPLayer):\n",
    "    def __init__(self, input_dims, output_dims, num_inducing=128, mean_type='constant'):\n",
    "        if output_dims is None:\n",
    "            inducing_points = torch.randn(num_inducing, input_dims)\n",
    "            batch_shape = torch.Size([])\n",
    "        else:\n",
    "            inducing_points = torch.randn(output_dims, num_inducing, input_dims)\n",
    "            batch_shape = torch.Size([output_dims])\n",
    "\n",
    "        variational_distribution = CholeskyVariationalDistribution(\n",
    "            num_inducing_points=num_inducing,\n",
    "            batch_shape=batch_shape\n",
    "        )\n",
    "\n",
    "        variational_strategy = VariationalStrategy(\n",
    "            self,\n",
    "            inducing_points,\n",
    "            variational_distribution,\n",
    "            learn_inducing_locations=True\n",
    "        )\n",
    "\n",
    "        super(DeepGPHiddenLayer, self).__init__(variational_strategy, input_dims, output_dims)\n",
    "\n",
    "        if mean_type == 'constant':\n",
    "            self.mean_module = ConstantMean(batch_shape=batch_shape)\n",
    "        else:\n",
    "            self.mean_module = LinearMean(input_dims)\n",
    "        self.covar_module = ScaleKernel(\n",
    "            RBFKernel(batch_shape=batch_shape, ard_num_dims=input_dims),\n",
    "            batch_shape=batch_shape, ard_num_dims=None\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "    def __call__(self, x, *other_inputs, **kwargs):\n",
    "        \"\"\"\n",
    "        Overriding __call__ isn't strictly necessary, but it lets us add concatenation based skip connections\n",
    "        easily. For example, hidden_layer2(hidden_layer1_outputs, inputs) will pass the concatenation of the first\n",
    "        hidden layer's outputs and the input data to hidden_layer2.\n",
    "        \"\"\"\n",
    "        if len(other_inputs):\n",
    "            if isinstance(x, gpytorch.distributions.MultitaskMultivariateNormal):\n",
    "                x = x.rsample()\n",
    "\n",
    "            processed_inputs = [\n",
    "                inp.unsqueeze(0).expand(gpytorch.settings.num_likelihood_samples.value(), *inp.shape)\n",
    "                for inp in other_inputs\n",
    "            ]\n",
    "\n",
    "            x = torch.cat([x] + processed_inputs, dim=-1)\n",
    "\n",
    "        return super().__call__(x, are_samples=bool(len(other_inputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697453a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepGP(DeepGP):\n",
    "    def __init__(self, X_train_shape):\n",
    "        hidden_layer = DeepGPHiddenLayer(\n",
    "            input_dims=X_train_shape[-1],\n",
    "            output_dims=num_hidden_dims,\n",
    "            mean_type='linear',\n",
    "        )\n",
    "\n",
    "        last_layer = DeepGPHiddenLayer(\n",
    "            input_dims=hidden_layer.output_dims,\n",
    "            output_dims=None,\n",
    "            mean_type='constant',\n",
    "        )\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_layer = hidden_layer\n",
    "        self.last_layer = last_layer\n",
    "        self.likelihood = GaussianLikelihood()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        hidden_rep1 = self.hidden_layer(inputs)\n",
    "        output = self.last_layer(hidden_rep1)\n",
    "        return output\n",
    "\n",
    "    def predict(self, test_loader):\n",
    "        with torch.no_grad():\n",
    "            mus = []\n",
    "            variances = []\n",
    "            lls = []\n",
    "            for x_batch, y_batch in test_loader:\n",
    "                preds = self.likelihood(self(x_batch))\n",
    "                mus.append(preds.mean)\n",
    "                variances.append(preds.variance)\n",
    "                lls.append(model.likelihood.log_marginal(y_batch, model(x_batch)))\n",
    "\n",
    "        return torch.cat(mus, dim=-1), torch.cat(variances, dim=-1), torch.cat(lls, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de06e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(final_df, idx):\n",
    "    device_indices = final_df[final_df.latitude==latitudes[idx]].index\n",
    "    device_df = jinja_df[jinja_df.device_number == device_ids[idx]]\n",
    "    assert(len(device_indices) == len(device_df)-device_df.pm2_5_calibrated_value.isna().sum())\n",
    "    \n",
    "    test_df = final_df.loc[device_indices]\n",
    "    assert(len(test_df.longitude.unique()) == 1)\n",
    "    \n",
    "    train_df = pd.concat([final_df, test_df]).drop_duplicates(keep=False)\n",
    "    assert(len(train_df.longitude.unique()) == len(longitudes)-1)\n",
    "    assert len(final_df) == len(test_df) + len(train_df)\n",
    "    \n",
    "    #defining the datasets\n",
    "    X_train = train_df.iloc[:, 0:-1]\n",
    "    y_train = train_df.iloc[:, -1]\n",
    "    X_train, y_train = torch.from_numpy(np.array(X_train)).float(), torch.from_numpy(np.array(y_train)).float()\n",
    "    \n",
    "    X_test = test_df.iloc[:, 0:-1]\n",
    "    y_test = test_df.iloc[:, -1]\n",
    "    X_test, y_test = torch.from_numpy(np.array(X_test)).float(), torch.from_numpy(np.array(y_test)).float()\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "    \n",
    "    #defining the model\n",
    "    model = DeepGP(X_train.shape)\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        \n",
    "    optimizer = torch.optim.Adam([{'params': model.parameters()},], lr=0.01)\n",
    "    mll = DeepApproximateMLL(VariationalELBO(model.likelihood, model, X_train.shape[-2]))\n",
    "    \n",
    "    #model training\n",
    "    epochs_iter = notebook.tqdm(range(num_epochs), desc='Epoch')\n",
    "    for i in epochs_iter:\n",
    "        minibatch_iter = notebook.tqdm(train_loader, desc='Minibatch', leave=False)\n",
    "        for x_batch, y_batch in minibatch_iter:\n",
    "            with gpytorch.settings.num_likelihood_samples(num_samples):\n",
    "                optimizer.zero_grad()\n",
    "                output = model(x_batch)\n",
    "                loss = -mll(output, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                minibatch_iter.set_postfix(loss=loss.item())\n",
    "    \n",
    "    #model evaluation\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1024)\n",
    "\n",
    "    model.eval()\n",
    "    predictive_means, predictive_variances, test_lls = model.predict(test_loader)\n",
    "    \n",
    "    rmse = sqrt(mean_squared_error(y_test, predictive_means.mean(0)))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57961ca8",
   "metadata": {},
   "source": [
    "#### Model training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54af595",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_list = []\n",
    "for i in range(len(latitudes)):\n",
    "    rmse = cross_validation(final_df, i)\n",
    "    rmse_list.append(rmse)\n",
    "    print(f'{device_ids[i]} successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4f5889",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rmse = np.mean(rmse_list)          \n",
    "mean_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830130db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d0f4ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
